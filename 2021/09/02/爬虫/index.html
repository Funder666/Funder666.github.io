<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Python爬虫学习笔记, Restart的部落格">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Python爬虫学习笔记 | Restart的部落格</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    	      
    <link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css">
    <script src="//cdn.jsdelivr.net/gh/stevenjoezhang/live2d-widget/autoload.js"></script>    

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 5.4.0"></head>



   <style>
    body{
       background-image: url(https://cdn.jsdelivr.net/gh/Tokisaki-Galaxy/res/site/medias/background.jpg);
       background-repeat:no-repeat;
       background-size:cover;
       background-attachment:fixed;
    }
</style>



<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Restart的部落格</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Restart的部落格</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Funder666/Funder666.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Funder666/Funder666.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/23.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Python爬虫学习笔记</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E7%88%AC%E8%99%AB/">
                                <span class="chip bg-color">爬虫</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2021-09-02
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    6.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    30 分
                </div>
                

                
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <p>​    在大一夏季学期至军训期间，闲暇之时想学点有意思的东西。既能让我产生兴趣，又能够促进我对于编程语言的学习，爬虫绝对是一个很好的选择。</p>
<span id="more"></span>

<h1 id="爬虫简介"><a href="#爬虫简介" class="headerlink" title="爬虫简介"></a>爬虫简介</h1><h2 id="——-爬虫初识"><a href="#——-爬虫初识" class="headerlink" title="—— 爬虫初识"></a>—— 爬虫初识</h2><p>什么是爬虫：编写程序，模拟浏览器上网，然后让其去互联网上抓取数据的过程。</p>
<p>爬虫的价值：<br>                    — 实际应用<br>                    — 就业</p>
<p>爬虫究竟是合法的还是违法的？<br>— 在法律中是不被禁止的<br>— 具有违法风险<br>— 善意爬虫    恶意爬虫</p>
<p>爬虫带来的风险体现在如下两方面：<br>— 爬虫干扰了被访问网站的正常运营<br>— 爬虫抓取了受到法律保护的特定类型的数据或信息</p>
<p>如何在使用编写爬虫的过程中避免进入局子的厄运呢？<br>— 时常的优化自己的程序，避免干扰被访问网站的正常运行<br>— 在使用，转播爬取到的数据时，审查抓取到的内容，如果发现了涉及到用户隐私和商业机密等内容，及时停止爬取和转播</p>
<p>爬虫在使用场景中的分类<br>            — 通用爬虫<br>                        抓取系统重要组成部分。抓取的是一整张页面数据<br>            — 聚焦爬虫<br>                        是建立在通用爬虫的基础之上。抓取的是页面中特定的局部内容<br>            — 增量式爬虫<br>                        检测网站中数据跟新的情况。只会抓取网站中最新更新出来的数据</p>
<p>反爬机制<br>    门户网站，可以通过制定相应的策略或者技术手段，防止爬虫程序进行网站数据的爬取。</p>
<p>反反爬策略<br>    爬虫程序可以通过制定相关的策略或者技术手段，破解门户网站中具备的反爬机制，从而可以获取门户网站中相关的数据</p>
<p>robots.txt协议<br>    君子协议。规定了网站中哪些数据可以被爬虫爬取哪些数据不可以被爬取。、</p>
<h2 id="——-http-amp-https协议"><a href="#——-http-amp-https协议" class="headerlink" title="—— http&amp;https协议"></a>—— http&amp;https协议</h2><p>http协议<br>    —概念：就是服&lt;font color=器和客户端进行数据交互的一种形式</p>
<p>常见的请求头信息:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">accept:浏览器通过这个头告诉服务器，它所支持的数据类型</span><br><span class="line">Accept-Charset: 浏览器通过这个头告诉服务器，它支持哪种字符集</span><br><span class="line">Accept-Encoding：浏览器通过这个头告诉服务器，支持的压缩格式</span><br><span class="line">Accept-Language：浏览器通过这个头告诉服务器，它的语言环境</span><br><span class="line">Host：浏览器通过这个头告诉服务器，想访问哪台主机</span><br><span class="line">If-Modified-Since: 浏览器通过这个头告诉服务器，缓存数据的时间</span><br><span class="line">Referer：浏览器通过这个头告诉服务器，客户机是哪个页面来的 防盗链</span><br><span class="line">Connection：浏览器通过这个头告诉服务器，请求完后是断开链接还是何持链接</span><br><span class="line">X-Requested-With: XMLHttpRequest 代表通过ajax方式进行访问</span><br><span class="line">User-Agent：请求载体的身份标识</span><br></pre></td></tr></table></figure>

<p>常见的相应头信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Location: 服务器通过这个头，来告诉浏览器跳到哪里</span><br><span class="line">Server：服务器通过这个头，告诉浏览器服务器的型号</span><br><span class="line">Content-Encoding：服务器通过这个头，告诉浏览器，数据的压缩格式</span><br><span class="line">Content-Length: 服务器通过这个头，告诉浏览器回送数据的长度</span><br><span class="line">Content-Language: 服务器通过这个头，告诉浏览器语言环境</span><br><span class="line">Content-<span class="type">Type</span>：服务器通过这个头，告诉浏览器回送数据的类型</span><br><span class="line">Refresh：服务器通过这个头，告诉浏览器定时刷新</span><br><span class="line">Content-Disposition: 服务器通过这个头，告诉浏览器以下载方式打数据</span><br><span class="line">Transfer-Encoding：服务器通过这个头，告诉浏览器数据是以分块方式回送的</span><br><span class="line">Expires: -<span class="number">1</span> 控制浏览器不要缓存</span><br><span class="line">Cache-Control: no-cache </span><br><span class="line">Pragma: no-cache</span><br></pre></td></tr></table></figure>

<p>HTTPS协议<br>    — 安全超文本传输协议，HTTPS是在HTTP上建立SSL加密层，并对传输数据进行加密，是HTTP协议的安全版。</p>
<p>加密方式</p>
<ol>
<li><p>对称密钥加密</p>
<ul>
<li>客服端传送信息和密钥给服务器</li>
<li>加密和解密是同一个密钥</li>
</ul>
<p>信息有被挟持、密钥有被破解的风险</p>
</li>
<li><p>非对称密钥加密</p>
<ul>
<li><p>服务器将公钥给客户端</p>
</li>
<li><p>客户端用公钥加密后将信息传给服务器</p>
</li>
<li><p>服务器用私钥解密</p>
</li>
</ul>
<p>公钥可能被挟持篡改</p>
</li>
<li><p> 证书密钥加密</p>
</li>
</ol>
<ul>
<li>服务器将公钥给证书认证机构签名</li>
<li>机构将签好名的公钥给客户端</li>
<li>客户端用公钥加密后发送给服务器，服务器用私钥解密</li>
</ul>
<p>   证书的数字签名难以伪造</p>
<h1 id="Requests-库"><a href="#Requests-库" class="headerlink" title="Requests 库"></a>Requests 库</h1><p>requests模块<br>    —python中原生的基于网络请求的模块，其主要作用是用来模拟浏览器发起请求。功能强大，用法简洁高效。在爬虫领域中占据着半壁江山的地位。</p>
<p>使用步骤：</p>
<ul>
<li>指定url</li>
<li>发起请求</li>
<li>获取响应数据</li>
<li>持久化存储</li>
</ul>
<p>第一个爬虫程序：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导包</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="comment">#step_1:指定url</span></span><br><span class="line">url = <span class="string">&#x27;https://www.sogou.com/&#x27;</span></span><br><span class="line"><span class="comment">#step_2:发起请求:使用get方法发起get请求，该方法会返回一个响应对象。参数url表示请求对应的url</span></span><br><span class="line">response = requests.get(url=url)</span><br><span class="line"><span class="comment">#step_3:获取响应数据:通过调用响应对象的text属性，返回响应对象中存储的字符串形式的响应数据（页面源码数据）</span></span><br><span class="line">page_text = response.text</span><br><span class="line"><span class="comment">#step_4:持久化存储</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./sogou.html&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(page_text)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;爬取数据完毕！！！&#x27;</span>)</span><br></pre></td></tr></table></figure>







<h2 id="——-简易网站采集器"><a href="#——-简易网站采集器" class="headerlink" title="—— 简易网站采集器"></a>—— 简易网站采集器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># UA伪装：将对应的User_Agent封装到一个字典中</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">    url = <span class="string">&#x27;https://www.sogou.com/web&#x27;</span></span><br><span class="line">    <span class="comment"># 处理url携带的参数:封装到字典中</span></span><br><span class="line">    kw = <span class="built_in">input</span>(<span class="string">&quot;enter a word:&quot;</span>)</span><br><span class="line">    param = &#123;<span class="string">&#x27;query&#x27;</span>: kw&#125;</span><br><span class="line">    <span class="comment"># 对指定的url发起的请求对应的url是携带参数的，并且请求过程中处理了参数</span></span><br><span class="line">    response = requests.get(url=url, params=param,headers=headers)</span><br><span class="line">    page_text=response.text</span><br><span class="line">    fileName=kw+<span class="string">&#x27;.html&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(fileName,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)<span class="keyword">as</span> fp:</span><br><span class="line">        fp.write(page_text)</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="built_in">print</span>(fileName,<span class="string">&#x27;保存成功！！！&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="——-破解百度翻译-获取页面的局部数据"><a href="#——-破解百度翻译-获取页面的局部数据" class="headerlink" title="—— 破解百度翻译(获取页面的局部数据)"></a>—— 破解百度翻译(获取页面的局部数据)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 1.指定url</span></span><br><span class="line">    post_url = <span class="string">&#x27;https://fanyi.baidu.com/sug&#x27;</span></span><br><span class="line">    <span class="comment"># 2.UA伪装</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">    <span class="comment"># 3.post请求参数处理</span></span><br><span class="line">    word = <span class="built_in">input</span>(<span class="string">&#x27;enter a word:&#x27;</span>)</span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">&#x27;kw&#x27;</span>: word</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># 4.请求发送</span></span><br><span class="line">    response = requests.post(url=post_url, data=data, headers=headers)</span><br><span class="line">    <span class="comment"># 5.获取相应数据：json(）方法返回的是obj (如果确认响应数据类型是json类型的，才可以使用json(）)</span></span><br><span class="line">    dic_obj = response.json()</span><br><span class="line">    <span class="comment"># 6.持久化存储</span></span><br><span class="line">    fileName = word + <span class="string">&#x27;&#x27;</span></span><br><span class="line">    fp = <span class="built_in">open</span>(fileName, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    json.dump(dic_obj, fp=fp, ensure_ascii=<span class="literal">False</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;over!!!&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="——-豆瓣电影"><a href="#——-豆瓣电影" class="headerlink" title="—— 豆瓣电影"></a>—— 豆瓣电影</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://movie.douban.com/j/chart/top_list&#x27;</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">param = &#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;24&#x27;</span>,</span><br><span class="line">         <span class="string">&#x27;interval_id&#x27;</span>: <span class="string">&#x27;100:90&#x27;</span>,</span><br><span class="line">         <span class="string">&#x27;action&#x27;</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">         <span class="string">&#x27;start&#x27;</span>: <span class="string">&#x27;0&#x27;</span>,  <span class="comment"># 从库中的第几部电影去取</span></span><br><span class="line">         <span class="string">&#x27;limit&#x27;</span>: <span class="string">&#x27;20&#x27;</span>,  <span class="comment"># 一次取出的个数</span></span><br><span class="line">         &#125;</span><br><span class="line">response = requests.get(url=url, params=param, headers=headers)</span><br><span class="line">list_data = response.json()</span><br><span class="line">fp = <span class="built_in">open</span>(<span class="string">&#x27;douban.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">json.dump(list_data, fp=fp, ensure_ascii=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;over!!!&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h2 id="——-综合练习之药监总局"><a href="#——-综合练习之药监总局" class="headerlink" title="—— 综合练习之药监总局"></a>—— 综合练习之药监总局</h2><p>需求：爬取国家药品监督管理总局中中华人民共和国化妆品生产许可证相关数据</p>
<p>—— 动态加载数据</p>
<p>—— 首页中对应的企业信息数据是通过ajax动态请求到的</p>
<p>—— 通过对详情页url的观察发现：</p>
<p>​    — url的域名都是一样的，只有携带的参数（id）不一样</p>
<p>​    — id值可以从首页对应的ajax请求道德json串中获取</p>
<p>​    — 域名和id值拼接出一个完整的企业对应的详情页的url</p>
<p>—— 详情页的企业详情数也是动态加载出来的</p>
<p>​    — 观察后发现：</p>
<p>​        — 所有的post请求的url都是一样的，只有参数id值是不同的</p>
<p>​        — 如果我们可以批量获取多家企业的id后，就可以将id和url形成一个完整的详情页所对应的ajax请求的url</p>
<p>​        </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://scxk.nmpa.gov.cn:81/xk/itownet/portalAction.do?method=getXkzsList&#x27;</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">id_list = []  <span class="comment"># 存储企业的ID</span></span><br><span class="line">all_data_list = []</span><br><span class="line"><span class="comment"># 参数的封装</span></span><br><span class="line"><span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">6</span>):<span class="comment">#获取前6页的信息</span></span><br><span class="line">    page = <span class="built_in">str</span>(page)</span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">&#x27;on&#x27;</span>: <span class="string">&#x27; true&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;page&#x27;</span>: page,</span><br><span class="line">        <span class="string">&#x27;pageSize&#x27;</span>: <span class="string">&#x27; 15&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;productName&#x27;</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;conditionType&#x27;</span>: <span class="string">&#x27; 1&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;applyname&#x27;</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;applysn&#x27;</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    json_ids = requests.post(url=url, headers=headers, data=data).json()</span><br><span class="line">    <span class="keyword">for</span> dic <span class="keyword">in</span> json_ids[<span class="string">&#x27;list&#x27;</span>]:</span><br><span class="line">        id_list.append(dic[<span class="string">&#x27;ID&#x27;</span>])</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取企业详细数据</span></span><br><span class="line">    post_url = <span class="string">&#x27;http://scxk.nmpa.gov.cn:81/xk/itownet/portalAction.do?method=getXkzsById&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">id</span> <span class="keyword">in</span> id_list:</span><br><span class="line">        data = &#123;</span><br><span class="line">            <span class="string">&#x27;id&#x27;</span>: <span class="built_in">id</span></span><br><span class="line">        &#125;</span><br><span class="line">        detail_json=requests.post(url=post_url,headers=headers,data=data).json()</span><br><span class="line">        all_data_list.append(detail_json)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./allData.json&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    json.dump(all_data_list,fp=fp,ensure_ascii=<span class="literal">False</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;over!!!&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>​                    </p>
<h1 id="数据解析"><a href="#数据解析" class="headerlink" title="数据解析"></a>数据解析</h1><p>聚焦爬虫：爬取页面中指定的页面内容</p>
<p>​    — 编码流程：</p>
<p>​            — 指定url</p>
<p>​            — 发起请求</p>
<p>​            — 获取相应数据</p>
<p>​            — 数据解析</p>
<p>​            — 持久化存储</p>
<p>数据解析分类：</p>
<ul>
<li>正则</li>
<li>bs4</li>
<li>xpath</li>
</ul>
<p>数据解析原理概述：</p>
<p>​    —— 解析的局部的文本内容都会在标签之间或者标签对应的属性中进行存储</p>
<ol>
<li>进行指定标签的定位</li>
<li>标签或者标签对应的属性中存储的数据值进行提取（解析）</li>
</ol>
<p>​         </p>
<h2 id="——-正则解析"><a href="#——-正则解析" class="headerlink" title="—— 正则解析"></a>—— 正则解析</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 需求:爬取糗事百科中糗图板块下所有的糗图图片</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个文件夹，保存所有的图片</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;./qiutu/&#x27;</span>):</span><br><span class="line">    os.mkdir(<span class="string">&#x27;./qiutu/&#x27;</span>)</span><br><span class="line">url = <span class="string">&#x27;https://www.qiushibaike.com/imgrank/&#x27;</span></span><br><span class="line">headers = headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36&#x27;</span>&#125;</span><br><span class="line"><span class="comment"># 使用通用爬虫对一整张页面进行爬取</span></span><br><span class="line">page_text = requests.get(url=url, headers=headers).text</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用聚焦爬虫将页面中所有的糗图进行解析/爬取</span></span><br><span class="line">ex = <span class="string">&#x27;&lt;div class=&quot;thumb&quot;&gt;.*?&lt;img src=&quot;(.*?)&quot; alt.*?&lt;/div&gt;&#x27;</span></span><br><span class="line">img_src_list = re.findall(ex, page_text, re.S)</span><br><span class="line"><span class="keyword">for</span> src <span class="keyword">in</span> img_src_list:</span><br><span class="line">    <span class="comment"># 拼接处一个完整的图片url</span></span><br><span class="line">    src = <span class="string">&#x27;https:&#x27;</span> + src</span><br><span class="line">    <span class="comment"># 请求到了图片的二进制数据</span></span><br><span class="line">    img_data = requests.get(url=src, headers=headers).content</span><br><span class="line">    <span class="comment"># 生成图片名称</span></span><br><span class="line">    img_name = src.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 图片存储的路径</span></span><br><span class="line">    imgPath = <span class="string">&#x27;./qiutu/&#x27;</span> + img_name</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(imgPath, <span class="string">&#x27;wb&#x27;</span>)<span class="keyword">as</span> fp:</span><br><span class="line">        fp.write(img_data)</span><br><span class="line">        <span class="built_in">print</span>(img_name, <span class="string">&#x27;下载成功!!!&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="——-BS4解析"><a href="#——-BS4解析" class="headerlink" title="—— BS4解析"></a>—— BS4解析</h2><p>​    </p>
<p>bs4进行数据解析</p>
<ul>
<li><p>数据解析的原理：</p>
<ul>
<li><p>1.标签定位</p>
</li>
<li><p>2.提取标签、标签属性中存储的数据值</p>
<ul>
<li>bs4数据解析的原理：</li>
</ul>
</li>
<li><p>1.实例化一个BeautifulSoup对象，并且将页面源码数据加载到该对象中</p>
</li>
<li><p>2.通过调用BeautifulSoup对象中相关的属性或者方法进行标签定位和数据提取</p>
<ul>
<li>环境安装：</li>
</ul>
</li>
<li><p>pip install bs4</p>
</li>
<li><p>pip install lxml</p>
<ul>
<li>如何实例化BeautifulSoup对象：</li>
</ul>
</li>
<li><p>from bs4 import BeautifulSoup</p>
</li>
<li><p>对象的实例化：</p>
<ul>
<li>1.将本地的html文档中的数据加载到该对象中<pre><code>  fp = open(&#39;./test.html&#39;,&#39;r&#39;,encoding=&#39;utf-8&#39;)
  soup = BeautifulSoup(fp,&#39;lxml&#39;)
</code></pre>
</li>
<li>2.将互联网上获取的页面源码加载到该对象中<pre><code>  page_text = response.text
  soup = BeatifulSoup(page_text,&#39;lxml&#39;)
</code></pre>
</li>
</ul>
</li>
<li><p>提供的用于数据解析的方法和属性：</p>
<ul>
<li>soup.tagName:返回的是文档中第一次出现的tagName对应的标签</li>
<li>soup.find():<ul>
<li>find(‘tagName’):等同于soup.div</li>
<li>属性定位：<br>  -soup.find(‘div’,class_/id/attr=’song’)</li>
</ul>
</li>
<li>soup.find_all(‘tagName’):返回符合要求的所有标签（列表）</li>
</ul>
</li>
<li><p>select：</p>
<ul>
<li>select(‘某种选择器（id，class，标签…选择器）’),返回的是一个列表。</li>
<li>层级选择器：<ul>
<li>soup.select(‘.tang &gt; ul &gt; li &gt; a’)：&gt;表示的是一个层级</li>
<li>oup.select(‘.tang &gt; ul a’)：空格表示的多个层级</li>
</ul>
</li>
</ul>
</li>
<li><p>获取标签之间的文本数据：</p>
<ul>
<li>soup.a.text/string/get_text()</li>
<li>text/get_text():可以获取某一个标签中所有的文本内容</li>
<li>string：只可以获取该标签下面直系的文本内容</li>
</ul>
</li>
<li><p>获取标签中属性值：</p>
<ul>
<li>soup.a[‘href’]</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment">#需求：爬取三国演义小说所有的章节标题和章节内容http://www.shicimingju.com/book/sanguoyanyi.html</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment">#对首页的页面数据进行爬取</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.121 Safari/537.36&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    url = <span class="string">&#x27;http://www.shicimingju.com/book/sanguoyanyi.html&#x27;</span></span><br><span class="line">    page_text = requests.get(url=url,headers=headers).text</span><br><span class="line"></span><br><span class="line">    <span class="comment">#在首页中解析出章节的标题和详情页的url</span></span><br><span class="line">    <span class="comment">#1.实例化BeautifulSoup对象，需要将页面源码数据加载到该对象中</span></span><br><span class="line">    soup = BeautifulSoup(page_text,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">    <span class="comment">#解析章节标题和详情页的url</span></span><br><span class="line">    li_list = soup.select(<span class="string">&#x27;.book-mulu &gt; ul &gt; li&#x27;</span>)</span><br><span class="line">    fp = <span class="built_in">open</span>(<span class="string">&#x27;./sanguo.txt&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">        title = li.a.string</span><br><span class="line">        detail_url = <span class="string">&#x27;http://www.shicimingju.com&#x27;</span>+li.a[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">        <span class="comment">#对详情页发起请求，解析出章节内容</span></span><br><span class="line">        detail_page_text = requests.get(url=detail_url,headers=headers).text</span><br><span class="line">        <span class="comment">#解析出详情页中相关的章节内容</span></span><br><span class="line">        detail_soup = BeautifulSoup(detail_page_text,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">        div_tag = detail_soup.find(<span class="string">&#x27;div&#x27;</span>,class_=<span class="string">&#x27;chapter_content&#x27;</span>)</span><br><span class="line">        <span class="comment">#解析到了章节的内容</span></span><br><span class="line">        content = div_tag.text</span><br><span class="line">        fp.write(title+<span class="string">&#x27;:&#x27;</span>+content+<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(title,<span class="string">&#x27;爬取成功！！！&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="——-Xpath解析"><a href="#——-Xpath解析" class="headerlink" title="—— Xpath解析"></a>—— Xpath解析</h2><ul>
<li>xpath解析原理：<ul>
<li>1.实例化一个etree的对象，且需要将被解析的页面源码数据加载到该对象中。</li>
<li>2.调用etree对象中的xpath方法结合着xpath表达式实现标签的定位和内容的捕获。</li>
</ul>
</li>
<li>环境的安装：<ul>
<li>pip install lxml</li>
</ul>
</li>
<li>如何实例化一个etree对象:from lxml import etree<ul>
<li>1.将本地的html文档中的源码数据加载到etree对象中：<br>  etree.parse(filePath)</li>
<li>2.可以将从互联网上获取的源码数据加载到该对象中<br>  etree.HTML(‘page_text’)</li>
<li>xpath(‘xpath表达式’)</li>
</ul>
</li>
<li>xpath表达式:<ul>
<li>/:表示的是从根节点开始定位。表示的是一个层级。</li>
<li>//:表示的是多个层级。可以表示从任意位置开始定位。</li>
<li>属性定位：//div[@class=’song’] tag[@attrName=”attrValue”]</li>
<li>索引定位：//div[@class=”song”]/p[3] 索引是从1开始的。</li>
<li>取文本：<ul>
<li>/text() 获取的是标签中直系的文本内容</li>
<li>//text() 标签中非直系的文本内容（所有的文本内容）</li>
</ul>
</li>
<li>取属性：<br>  /@attrName     ==&gt;img/src</li>
</ul>
</li>
</ul>
<h3 id="——-二手房标题获取"><a href="#——-二手房标题获取" class="headerlink" title="—— 二手房标题获取"></a>—— 二手房标题获取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">url=<span class="string">&#x27;https://bj.58.com/ershoufang/&#x27;</span></span><br><span class="line">page_text=requests.get(url=url,headers=headers).text</span><br><span class="line">tree = etree.HTML(page_text)</span><br><span class="line">h3_list=tree.xpath(<span class="string">&#x27;//section[@class=&quot;list&quot;]//a//div[@class=&quot;property-content-title&quot;]/h3&#x27;</span>)</span><br><span class="line">fp = <span class="built_in">open</span>(<span class="string">&#x27;58text&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> h3 <span class="keyword">in</span> h3_list:</span><br><span class="line">    title =h3.xpath(<span class="string">&#x27;./text()&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="built_in">print</span>(title)</span><br><span class="line">    fp.write(title+<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="——-4k美女图片获取"><a href="#——-4k美女图片获取" class="headerlink" title="—— 4k美女图片获取"></a>—— 4k美女图片获取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python </span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment">#需求：解析下载图片数据 http://pic.netbian.com/4kmeinv/</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    url = <span class="string">&#x27;http://pic.netbian.com/4kmeinv/&#x27;</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    response = requests.get(url=url,headers=headers)</span><br><span class="line">    <span class="comment">#手动设定响应数据的编码格式</span></span><br><span class="line">    <span class="comment"># response.encoding = &#x27;utf-8&#x27;</span></span><br><span class="line">    page_text = response.text</span><br><span class="line"></span><br><span class="line">    <span class="comment">#数据解析：src的属性值  alt属性</span></span><br><span class="line">    tree = etree.HTML(page_text)</span><br><span class="line">    li_list = tree.xpath(<span class="string">&#x27;//div[@class=&quot;slist&quot;]/ul/li&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">#创建一个文件夹</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;./picLibs&#x27;</span>):</span><br><span class="line">        os.mkdir(<span class="string">&#x27;./picLibs&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">        img_src = <span class="string">&#x27;http://pic.netbian.com&#x27;</span>+li.xpath(<span class="string">&#x27;./a/img/@src&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">        img_name = li.xpath(<span class="string">&#x27;./a/img/@alt&#x27;</span>)[<span class="number">0</span>]+<span class="string">&#x27;.jpg&#x27;</span></span><br><span class="line">        <span class="comment">#通用处理中文乱码的解决方案</span></span><br><span class="line">        img_name = img_name.encode(<span class="string">&#x27;iso-8859-1&#x27;</span>).decode(<span class="string">&#x27;gbk&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print(img_name,img_src)</span></span><br><span class="line">        <span class="comment">#请求图片进行持久化存储</span></span><br><span class="line">        img_data = requests.get(url=img_src,headers=headers).content</span><br><span class="line">        img_path = <span class="string">&#x27;picLibs/&#x27;</span>+img_name</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(img_path,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            fp.write(img_data)</span><br><span class="line">            <span class="built_in">print</span>(img_name,<span class="string">&#x27;下载成功！！！&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="异步爬虫"><a href="#异步爬虫" class="headerlink" title="异步爬虫"></a>异步爬虫</h1><p>高性能异步爬虫<br>目的：在爬虫中使用异步实现高性能的数据爬取操作。</p>
<p>异步爬虫的方式：</p>
<p>1.多线程，多进程（不建议）：<br>好处：可以为相关阻塞的操作单独开启线程或者进程，阻塞操作就可以异步执行。<br>弊端：无法无限制的开启多线程或者多进程。</p>
<p>2.线程池、进程池（适当的使用）：<br>好处：我们可以降低系统对进程或者线程创建和销毁的一个频率，从而很好的降低系统的开销。<br>弊端：池中线程或进程的数量是有上限。</p>
<h2 id="——-线程池"><a href="#——-线程池" class="headerlink" title="—— 线程池"></a>—— 线程池</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#线程池的基本使用</span></span><br><span class="line"><span class="comment"># import time</span></span><br><span class="line"><span class="comment"># #使用单线程串行方式执行</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># def get_page(str):</span></span><br><span class="line"><span class="comment">#     print(&quot;正在下载 ：&quot;,str)</span></span><br><span class="line"><span class="comment">#     time.sleep(2)</span></span><br><span class="line"><span class="comment">#     print(&#x27;下载成功：&#x27;,str)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># name_list =[&#x27;xiaozi&#x27;,&#x27;aa&#x27;,&#x27;bb&#x27;,&#x27;cc&#x27;]</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># start_time = time.time()</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># for i in range(len(name_list)):</span></span><br><span class="line"><span class="comment">#     get_page(name_list[i])</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># end_time = time.time()</span></span><br><span class="line"><span class="comment"># print(&#x27;%d second&#x27;% (end_time-start_time))</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="comment">#导入线程池模块对应的类</span></span><br><span class="line"><span class="keyword">from</span> multiprocessing.dummy <span class="keyword">import</span> Pool</span><br><span class="line"><span class="comment">#使用线程池方式执行</span></span><br><span class="line">start_time = time.time()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_page</span>(<span class="params"><span class="built_in">str</span></span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;正在下载 ：&quot;</span>,<span class="built_in">str</span>)</span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;下载成功：&#x27;</span>,<span class="built_in">str</span>)</span><br><span class="line"></span><br><span class="line">name_list =[<span class="string">&#x27;xiaozi&#x27;</span>,<span class="string">&#x27;aa&#x27;</span>,<span class="string">&#x27;bb&#x27;</span>,<span class="string">&#x27;cc&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#实例化一个线程池对象</span></span><br><span class="line">pool = Pool(<span class="number">4</span>)</span><br><span class="line"><span class="comment">#将列表中每一个列表元素传递给get_page进行处理。</span></span><br><span class="line">pool.<span class="built_in">map</span>(get_page,name_list)</span><br><span class="line">pool.close()</span><br><span class="line">pool.join()</span><br><span class="line">end_time = time.time()</span><br><span class="line"><span class="built_in">print</span>(end_time-start_time)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="——-梨视频爬取"><a href="#——-梨视频爬取" class="headerlink" title="—— 梨视频爬取"></a>—— 梨视频爬取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> multiprocessing.dummy <span class="keyword">import</span> Pool</span><br><span class="line"><span class="comment">#需求：爬取梨视频的视频数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#原则：线程池处理的是阻塞且较为耗时的操作</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#对下述url发起请求解析出视频详情页的url和视频的名称</span></span><br><span class="line">url = <span class="string">&#x27;https://www.pearvideo.com/category_5&#x27;</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">page_text = requests.get(url=url,headers=headers).text</span><br><span class="line"></span><br><span class="line">tree = etree.HTML(page_text)</span><br><span class="line">li_list = tree.xpath(<span class="string">&#x27;//ul[@id=&quot;listvideoListUl&quot;]/li&#x27;</span>)</span><br><span class="line">urls = [] <span class="comment">#存储所有视频的链接and名字</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;./LSP&#x27;</span>):</span><br><span class="line">    os.mkdir(<span class="string">&#x27;./LSP&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">    <span class="built_in">id</span> = li.xpath(<span class="string">&#x27;./div/a/@href&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">    contId = <span class="built_in">id</span>.replace(<span class="string">&#x27;video_&#x27;</span>,<span class="string">&quot;&quot;</span>)</span><br><span class="line">    contId2 = <span class="string">&#x27;cont-&#x27;</span>+<span class="built_in">str</span>(contId)</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Referer&#x27;</span>: <span class="string">&#x27;https://www.pearvideo.com/video_&#x27;</span>+ <span class="built_in">str</span>(contId)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">#获取动态url(ajax)</span></span><br><span class="line">    dynamic_url = <span class="string">&#x27;https://www.pearvideo.com/videoStatus.jsp?contId=&#x27;</span>+contId</span><br><span class="line">    name = li.xpath(<span class="string">&#x27;./div/a/div[2]/text()&#x27;</span>)[<span class="number">0</span>]+<span class="string">&#x27;.mp4&#x27;</span></span><br><span class="line">    <span class="comment">#对动态url发起请求</span></span><br><span class="line">    dynamic_page_text = requests.get(url=dynamic_url,headers=headers).text</span><br><span class="line">    <span class="comment">#从动态页中解析出视频的伪url</span></span><br><span class="line">    ex = <span class="string">&#x27;&quot;srcUrl&quot;:&quot;(.*?)&quot;&#x27;</span></span><br><span class="line">    srcUrl=re.findall(ex,dynamic_page_text)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment">#替换视频里面的时间戳，获取真url</span></span><br><span class="line">    video_url = srcUrl.replace(srcUrl.split(<span class="string">&quot;-&quot;</span>)[<span class="number">0</span>].split(<span class="string">&quot;/&quot;</span>)[-<span class="number">1</span>], contId2)</span><br><span class="line">    dic = &#123;</span><br><span class="line">        <span class="string">&#x27;name&#x27;</span>:name,</span><br><span class="line">        <span class="string">&#x27;url&#x27;</span>:video_url</span><br><span class="line">    &#125;</span><br><span class="line">    urls.append(dic)</span><br><span class="line"><span class="comment">#对视频链接发起请求获取视频的二进制数据，然后将视频数据进行返回</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_video_data</span>(<span class="params">dic</span>):</span></span><br><span class="line">    url = dic[<span class="string">&#x27;url&#x27;</span>]</span><br><span class="line">    <span class="built_in">print</span>(dic[<span class="string">&#x27;name&#x27;</span>],<span class="string">&#x27;正在下载......&#x27;</span>)</span><br><span class="line">    data = requests.get(url=url,headers=headers).content</span><br><span class="line">    <span class="comment">#持久化存储操作</span></span><br><span class="line">    path = <span class="string">&#x27;LSP/&#x27;</span>+dic[<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">        fp.write(data)</span><br><span class="line">        <span class="built_in">print</span>(dic[<span class="string">&#x27;name&#x27;</span>],<span class="string">&#x27;下载成功！&#x27;</span>)</span><br><span class="line"><span class="comment">#使用线程池对视频数据进行请求（较为耗时的阻塞操作）</span></span><br><span class="line">pool = Pool(<span class="number">4</span>)</span><br><span class="line">pool.<span class="built_in">map</span>(get_video_data,urls)</span><br><span class="line"></span><br><span class="line">pool.close()</span><br><span class="line">pool.join()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="——-异步协程（未完待续）"><a href="#——-异步协程（未完待续）" class="headerlink" title="—— 异步协程（未完待续）"></a>—— 异步协程（未完待续）</h2><p>​    3.单线程+异步协程（推荐）：<br>​    event_loop：事件循环，相当于一个无限循环，我们可以把一些函数注册到这个事件循环上，<br>​    当满足某些条件的时候，函数就会被循环执行。</p>
<p>​    coroutine：协程对象，我们可以将协程对象注册到事件循环中，它会被事件循环调用。<br>​    我们可以使用 async 关键字来定义一个方法，这个方法在调用时不会立即被执行，而是返回<br>​    一个协程对象。</p>
<p>​    task：任务，它是对协程对象的进一步封装，包含了任务的各个状态。</p>
<p>​    future：代表将来执行或还没有执行的任务，实际上和 task 没有本质区别。</p>
<p>​    async 定义一个协程.</p>
<p>​    await 用来挂起阻塞方法的执行。</p>
<h1 id="Selenium"><a href="#Selenium" class="headerlink" title="Selenium"></a>Selenium</h1><p>selenium库相关的知识和用法，有一位学长总结的非常好，在此附上链接</p>
<p><a target="_blank" rel="noopener" href="https://shu-chasing.github.io/WEB%E8%87%AA%E5%8A%A8%E5%8C%96%E7%AC%94%E8%AE%B0/">https://shu-chasing.github.io/WEB%E8%87%AA%E5%8A%A8%E5%8C%96%E7%AC%94%E8%AE%B0/</a></p>
<p>这里就记录用selenium库完成的一些实操：</p>
<h2 id="——-模拟QQ登录："><a href="#——-模拟QQ登录：" class="headerlink" title="—— 模拟QQ登录："></a>—— 模拟QQ登录：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"></span><br><span class="line">bro = webdriver.Chrome(executable_path=<span class="string">&#x27;./chromedriver&#x27;</span>)</span><br><span class="line"></span><br><span class="line">bro.get(<span class="string">&#x27;https://qzone.qq.com/&#x27;</span>)</span><br><span class="line"></span><br><span class="line">bro.switch_to.frame(<span class="string">&#x27;login_frame&#x27;</span>)</span><br><span class="line"></span><br><span class="line">a_tag = bro.find_element_by_id(<span class="string">&quot;switcher_plogin&quot;</span>)</span><br><span class="line">a_tag.click()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">userName_tag = bro.find_element_by_id(<span class="string">&#x27;u&#x27;</span>)</span><br><span class="line">password_tag = bro.find_element_by_id(<span class="string">&#x27;p&#x27;</span>)</span><br><span class="line">sleep(<span class="number">1</span>)</span><br><span class="line">userName_tag.send_keys(<span class="string">&#x27;328410948&#x27;</span>)</span><br><span class="line">sleep(<span class="number">1</span>)</span><br><span class="line">password_tag.send_keys(<span class="string">&#x27;123456789&#x27;</span>)</span><br><span class="line">sleep(<span class="number">1</span>)</span><br><span class="line">btn = bro.find_element_by_id(<span class="string">&#x27;login_button&#x27;</span>)</span><br><span class="line">btn.click()</span><br><span class="line"></span><br><span class="line">sleep(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">bro.quit()</span><br></pre></td></tr></table></figure>



<h2 id="——-无头浏览器-规避检测："><a href="#——-无头浏览器-规避检测：" class="headerlink" title="—— 无头浏览器+规避检测："></a>—— 无头浏览器+规避检测：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"><span class="comment">#实现无可视化界面</span></span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.chrome.options <span class="keyword">import</span> Options</span><br><span class="line"><span class="comment">#实现规避检测</span></span><br><span class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> ChromeOptions</span><br><span class="line"></span><br><span class="line"><span class="comment">#实现无可视化界面的操作</span></span><br><span class="line">chrome_options = Options()</span><br><span class="line">chrome_options.add_argument(<span class="string">&#x27;--headless&#x27;</span>)</span><br><span class="line">chrome_options.add_argument(<span class="string">&#x27;--disable-gpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#实现规避检测</span></span><br><span class="line">option = ChromeOptions()</span><br><span class="line">option.add_experimental_option(<span class="string">&#x27;excludeSwitches&#x27;</span>, [<span class="string">&#x27;enable-automation&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#如何实现让selenium规避被检测到的风险</span></span><br><span class="line">bro = webdriver.Chrome(executable_path=<span class="string">&#x27;./chromedriver&#x27;</span>,chrome_options=chrome_options,options=option)</span><br><span class="line"></span><br><span class="line"><span class="comment">#无可视化界面（无头浏览器） phantomJs</span></span><br><span class="line">bro.get(<span class="string">&#x27;https://www.baidu.com&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(bro.page_source)</span><br><span class="line">sleep(<span class="number">2</span>)</span><br><span class="line">bro.quit()</span><br></pre></td></tr></table></figure>



<h2 id="——-12306模拟登录"><a href="#——-12306模拟登录" class="headerlink" title="—— 12306模拟登录"></a>—— 12306模拟登录</h2><pre><code>- 超级鹰：http://www.chaojiying.com/about.html
    - 注册：普通用户
    - 登录：普通用户
        - 题分查询：充值
        - 创建一个软件（id）
        - 下载示例代码

- 12306模拟登录编码流程：
    - 使用selenium打开登录页面
    - 对当前selenium打开的这张页面进行截图
    - 对当前图片局部区域（验证码图片）进行裁剪
        - 好处：将验证码图片和模拟登录进行一一对应。
    - 使用超级鹰识别验证码图片（坐标）
    - 使用动作链根据坐标实现点击操作
    - 录入用户名密码，点击登录按钮实现登录
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下述代码为超级鹰提供的示例代码</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> hashlib <span class="keyword">import</span> md5</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Chaojiying_Client</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, username, password, soft_id</span>):</span></span><br><span class="line">        self.username = username</span><br><span class="line">        password =  password.encode(<span class="string">&#x27;utf8&#x27;</span>)</span><br><span class="line">        self.password = md5(password).hexdigest()</span><br><span class="line">        self.soft_id = soft_id</span><br><span class="line">        self.base_params = &#123;</span><br><span class="line">            <span class="string">&#x27;user&#x27;</span>: self.username,</span><br><span class="line">            <span class="string">&#x27;pass2&#x27;</span>: self.password,</span><br><span class="line">            <span class="string">&#x27;softid&#x27;</span>: self.soft_id,</span><br><span class="line">        &#125;</span><br><span class="line">        self.headers = &#123;</span><br><span class="line">            <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;Keep-Alive&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0)&#x27;</span>,</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">PostPic</span>(<span class="params">self, im, codetype</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        im: 图片字节</span></span><br><span class="line"><span class="string">        codetype: 题目类型 参考 http://www.chaojiying.com/price.html</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        params = &#123;</span><br><span class="line">            <span class="string">&#x27;codetype&#x27;</span>: codetype,</span><br><span class="line">        &#125;</span><br><span class="line">        params.update(self.base_params)</span><br><span class="line">        files = &#123;<span class="string">&#x27;userfile&#x27;</span>: (<span class="string">&#x27;ccc.jpg&#x27;</span>, im)&#125;</span><br><span class="line">        r = requests.post(<span class="string">&#x27;http://upload.chaojiying.net/Upload/Processing.php&#x27;</span>, data=params, files=files, headers=self.headers)</span><br><span class="line">        <span class="keyword">return</span> r.json()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">ReportError</span>(<span class="params">self, im_id</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        im_id:报错题目的图片ID</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        params = &#123;</span><br><span class="line">            <span class="string">&#x27;id&#x27;</span>: im_id,</span><br><span class="line">        &#125;</span><br><span class="line">        params.update(self.base_params)</span><br><span class="line">        r = requests.post(<span class="string">&#x27;http://upload.chaojiying.net/Upload/ReportError.php&#x27;</span>, data=params, headers=self.headers)</span><br><span class="line">        <span class="keyword">return</span> r.json()</span><br><span class="line"></span><br><span class="line"><span class="comment"># chaojiying = Chaojiying_Client(&#x27;bobo328410948&#x27;, &#x27;bobo328410948&#x27;, &#x27;899370&#x27;)	#用户中心&gt;&gt;软件ID 生成一个替换 96001</span></span><br><span class="line"><span class="comment"># im = open(&#x27;12306.jpg&#x27;, &#x27;rb&#x27;).read()													#本地图片文件路径 来替换 a.jpg 有时WIN系统须要//</span></span><br><span class="line"><span class="comment"># print(chaojiying.PostPic(im, 9004)[&#x27;pic_str&#x27;])</span></span><br><span class="line"><span class="comment">#上述代码为超级鹰提供的示例代码</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#使用selenium打开登录页面</span></span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> ActionChains</span><br><span class="line"></span><br><span class="line">bro = webdriver.Chrome(executable_path=<span class="string">&#x27;./chromedriver&#x27;</span>)</span><br><span class="line">bro.implicitly_wait(<span class="number">10</span>)</span><br><span class="line">bro.get(<span class="string">&#x27;https://kyfw.12306.cn/otn/resources/login.html&#x27;</span>)</span><br><span class="line"><span class="comment">#将窗口最大化</span></span><br><span class="line">bro.maximize_window()</span><br><span class="line">time.sleep(<span class="number">0.5</span>)</span><br><span class="line">bro.find_element_by_link_text(<span class="string">&#x27;账号登录&#x27;</span>).click()</span><br><span class="line">time.sleep(<span class="number">1</span>)</span><br><span class="line"><span class="comment">#save_screenshot就是将当前页面进行截图且保存</span></span><br><span class="line">bro.save_screenshot(<span class="string">&#x27;aa.png&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#确定验证码图片对应的左上角和右下角的坐标（裁剪的区域就确定）</span></span><br><span class="line">code_img_ele = bro.find_element_by_class_name(<span class="string">&#x27;imgCode&#x27;</span>)</span><br><span class="line">location = code_img_ele.location  <span class="comment"># 验证码图片左上角的坐标 x,y</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;location:&#x27;</span>,location)</span><br><span class="line">size = code_img_ele.size  <span class="comment">#验证码标签对应的长和宽</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;size:&#x27;</span>,size)</span><br><span class="line"><span class="comment">#左上角和右下角坐标</span></span><br><span class="line"><span class="comment">#根据屏幕缩放比例乘相应倍数</span></span><br><span class="line">rangle = (</span><br><span class="line"><span class="built_in">int</span>(location[<span class="string">&#x27;x&#x27;</span>])*<span class="number">1.25</span>, <span class="built_in">int</span>(location[<span class="string">&#x27;y&#x27;</span>])*<span class="number">1.25</span>, <span class="built_in">int</span>(location[<span class="string">&#x27;x&#x27;</span>] + size[<span class="string">&#x27;width&#x27;</span>])*<span class="number">1.25</span>, <span class="built_in">int</span>(location[<span class="string">&#x27;y&#x27;</span>] + size[<span class="string">&#x27;height&#x27;</span>])*<span class="number">1.25</span>)</span><br><span class="line"><span class="comment">#至此验证码图片区域就确定下来了</span></span><br><span class="line"></span><br><span class="line">i = Image.<span class="built_in">open</span>(<span class="string">&#x27;./aa.png&#x27;</span>)</span><br><span class="line">code_img_name = <span class="string">&#x27;./code.png&#x27;</span></span><br><span class="line"><span class="comment">#crop根据指定区域进行图片裁剪</span></span><br><span class="line">frame = i.crop(rangle)</span><br><span class="line">frame.save(code_img_name)</span><br><span class="line"></span><br><span class="line"><span class="comment">#将验证码图片提交给超级鹰进行识别</span></span><br><span class="line">chaojiying = Chaojiying_Client(<span class="string">&#x27;20121048&#x27;</span>, <span class="string">&#x27;Restart1128&#x27;</span>, <span class="string">&#x27;920781&#x27;</span>)	<span class="comment">#用户中心&gt;&gt;软件ID 生成一个替换 96001</span></span><br><span class="line">im = <span class="built_in">open</span>(<span class="string">&#x27;code.png&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>).read()													<span class="comment">#本地图片文件路径 来替换 a.jpg 有时WIN系统须要//</span></span><br><span class="line"><span class="built_in">print</span>(chaojiying.PostPic(im, <span class="number">9004</span>)[<span class="string">&#x27;pic_str&#x27;</span>])</span><br><span class="line">result = chaojiying.PostPic(im, <span class="number">9004</span>)[<span class="string">&#x27;pic_str&#x27;</span>]</span><br><span class="line">all_list = [] <span class="comment">#要存储即将被点击的点的坐标  [[x1,y1],[x2,y2]]</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;|&#x27;</span> <span class="keyword">in</span> result:</span><br><span class="line">    list_1 = result.split(<span class="string">&#x27;|&#x27;</span>)</span><br><span class="line">    count_1 = <span class="built_in">len</span>(list_1)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(count_1):</span><br><span class="line">        xy_list = []</span><br><span class="line">        x = <span class="built_in">int</span>(list_1[i].split(<span class="string">&#x27;,&#x27;</span>)[<span class="number">0</span>])</span><br><span class="line">        y = <span class="built_in">int</span>(list_1[i].split(<span class="string">&#x27;,&#x27;</span>)[<span class="number">1</span>])</span><br><span class="line">        xy_list.append(x)</span><br><span class="line">        xy_list.append(y)</span><br><span class="line">        all_list.append(xy_list)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    x = <span class="built_in">int</span>(result.split(<span class="string">&#x27;,&#x27;</span>)[<span class="number">0</span>])</span><br><span class="line">    y = <span class="built_in">int</span>(result.split(<span class="string">&#x27;,&#x27;</span>)[<span class="number">1</span>])</span><br><span class="line">    xy_list = []</span><br><span class="line">    xy_list.append(x)</span><br><span class="line">    xy_list.append(y)</span><br><span class="line">    all_list.append(xy_list)</span><br><span class="line"><span class="built_in">print</span>(all_list)</span><br><span class="line"><span class="comment">#遍历列表，使用动作链对每一个列表元素对应的x,y指定的位置进行点击操作</span></span><br><span class="line"><span class="keyword">for</span> l <span class="keyword">in</span> all_list:</span><br><span class="line">    x = l[<span class="number">0</span>]</span><br><span class="line">    y = l[<span class="number">1</span>]</span><br><span class="line">    ActionChains(bro).move_to_element_with_offset(code_img_ele, x/<span class="number">1.25</span>, y/<span class="number">1.25</span>).click().perform()<span class="comment">#别忘了除以之前的倍数</span></span><br><span class="line">    time.sleep(<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">bro.find_element_by_id(<span class="string">&#x27;J-userName&#x27;</span>).send_keys(<span class="string">&#x27;Restart1128&#x27;</span>)</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line">bro.find_element_by_id(<span class="string">&#x27;J-password&#x27;</span>).send_keys(<span class="string">&#x27;Restart1128666&#x27;</span>)</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line">bro.find_element_by_id(<span class="string">&#x27;J-login&#x27;</span>).click()</span><br><span class="line">time.sleep(<span class="number">30</span>)</span><br></pre></td></tr></table></figure>



<h2 id="——-爬取梨视频"><a href="#——-爬取梨视频" class="headerlink" title="—— 爬取梨视频"></a>—— 爬取梨视频</h2><p>之前通过分析动态加载的页面，从ajax请求中获取mp4链接，还要辨别伪链接，十分麻烦，而通过使用selenium库，可以直接获取js渲染后的页面源码数据，不用再分析动态加载了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="comment">#实现规避检测</span></span><br><span class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> ChromeOptions</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment">#进行头部信息伪装</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    url = <span class="string">&#x27;https://www.pearvideo.com/category_8&#x27;</span></span><br><span class="line">    <span class="comment">#获取科技页面中最新的视频所包含的网站的li列表</span></span><br><span class="line">    page_text = requests.get(url=url,headers=headers).text</span><br><span class="line">    tree = etree.HTML(page_text)</span><br><span class="line">    li_list = tree.xpath(<span class="string">&#x27;//*[@id=&quot;listvideoListUl&quot;]/li&#x27;</span>)</span><br><span class="line">    <span class="comment">#print(li_list)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#规避检测</span></span><br><span class="line">    option = ChromeOptions()</span><br><span class="line">    option.add_experimental_option(<span class="string">&#x27;excludeSwitches&#x27;</span>, [<span class="string">&#x27;enable-automation&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    bro = webdriver.Chrome(executable_path=<span class="string">&#x27;./chromedriver&#x27;</span>, options=option)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">        <span class="comment">#对li列表循环获取每个最新视频的url</span></span><br><span class="line">        deta_url = <span class="string">&#x27;https://www.pearvideo.com/&#x27;</span> + li.xpath(<span class="string">&#x27;./div/a/@href&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">        name = li.xpath(<span class="string">&#x27;./div/a/div[2]/text()&#x27;</span>)[<span class="number">0</span>] + <span class="string">&#x27;.mp4&#x27;</span></span><br><span class="line">        <span class="comment">#利用浏览器对象访问每个视频页面</span></span><br><span class="line">        bro.get(deta_url)</span><br><span class="line">        <span class="comment"># page_source获取视频页面源码数据</span></span><br><span class="line">        page_text_mp4 = bro.page_source</span><br><span class="line">        <span class="comment">#生成etree对象来进行xpath解析</span></span><br><span class="line">        tree = etree.HTML(page_text_mp4)</span><br><span class="line">        <span class="comment">#提取页面数据中的MP4连接</span></span><br><span class="line">        mp4_url = tree.xpath(<span class="string">&#x27;//*[@id=&quot;JprismPlayer&quot;]/video/@src&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">        <span class="comment">#获取MP4的二进制数据并存储</span></span><br><span class="line">        mp4_rar = requests.get(url=mp4_url,headers=headers).content</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(name,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            fp.write(mp4_rar)</span><br><span class="line">            <span class="built_in">print</span>(name,<span class="string">&#x27;爬取成功!!&#x27;</span>)</span><br><span class="line">    <span class="comment">#关闭浏览器对象</span></span><br><span class="line">    bro.quit()</span><br></pre></td></tr></table></figure>


                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">Restart</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://Funder666.github.io/2021/09/02/%E7%88%AC%E8%99%AB/">http://Funder666.github.io/2021/09/02/%E7%88%AC%E8%99%AB/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">Restart</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E7%88%AC%E8%99%AB/">
                                    <span class="chip bg-color">爬虫</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2021/09/02/Mysql/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/16.jpg" class="responsive-img" alt="Mysql基础部分的学习">
                        
                        <span class="card-title">Mysql基础部分的学习</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            对于大数据专业来说，数据库的学习想必是不可或缺的。尽管通过知乎了解到，Mysql数据库只能处理较小的数据量，相较而言，Hbase,Hive数据库等实则更为重要。但我相信，Mysql作为如今最流行的数据库还是有学习的必要的，更何况，在掌握了其
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2021-09-02
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            Restart
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/">
                        <span class="chip bg-color">数据库</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2021/09/02/Python/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/22.jpg" class="responsive-img" alt="Python学习笔记">
                        
                        <span class="card-title">Python学习笔记</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                               在大一的时候我们学过了数据分析，可这其实只是对Python几个库的运用罢了，这使得我们对于Python语言的掌握还是非常粗浅的，这一点我在学习Python爬虫的时候深有体会。原本我以为自己有一定Python基础，便能直接进行爬虫的学习
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-09-02
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            Restart
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Python/">
                        <span class="chip bg-color">Python</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2021</span>
            
            <span id="year">2021</span>
            <a href="/about" target="_blank">Restart</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            
            
            
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2021";
                        var startMonth = "9";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link ">
    <a href="https://github.com/Funder666" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:841610078@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=841610078" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 841610078" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>
    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/node_modules/hexo-helper-live2dlib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"node_modules/hexo-helper-live2d","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/node_modules/hexo-helper-live2dassets/koharu.model.json"},"log":false});</script></body>

</html>
